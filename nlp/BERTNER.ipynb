{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 19 03:38:47 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.24       Driver Version: 528.24       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 47%   29C    P0   113W / 350W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1188    C+G   ...dows\\System32\\LogonUI.exe    N/A      |\n",
      "|    0   N/A  N/A      1212    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (4.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lkk68\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lkk68\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lkk68\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from scikit-learn) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: accelerate in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (0.20.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lkk68\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.6.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from torch>=1.6.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from torch>=1.6.0->accelerate) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from sympy->torch>=1.6.0->accelerate) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: evaluate in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: dill in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (2.13.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (12.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lkk68\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lkk68\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting xformers\n",
      "  Downloading xformers-0.0.20-cp39-cp39-win_amd64.whl (97.6 MB)\n",
      "     ---------------------------------------- 0.0/97.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.0/97.6 MB 21.8 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 4.4/97.6 MB 46.9 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 7.7/97.6 MB 61.8 MB/s eta 0:00:02\n",
      "     ---- ---------------------------------- 10.5/97.6 MB 72.6 MB/s eta 0:00:02\n",
      "     ----- --------------------------------- 13.5/97.6 MB 65.6 MB/s eta 0:00:02\n",
      "     ------ -------------------------------- 16.3/97.6 MB 59.5 MB/s eta 0:00:02\n",
      "     ------- ------------------------------- 19.2/97.6 MB 65.6 MB/s eta 0:00:02\n",
      "     -------- ------------------------------ 22.1/97.6 MB 59.5 MB/s eta 0:00:02\n",
      "     --------- ----------------------------- 25.0/97.6 MB 65.6 MB/s eta 0:00:02\n",
      "     ---------- ---------------------------- 27.5/97.6 MB 65.6 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 28.3/97.6 MB 59.8 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 31.1/97.6 MB 50.1 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 32.0/97.6 MB 43.7 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 35.0/97.6 MB 43.7 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 38.3/97.6 MB 46.7 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 41.4/97.6 MB 59.5 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 44.7/97.6 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 47.9/97.6 MB 72.6 MB/s eta 0:00:01\n",
      "     -------------------- ------------------ 51.1/97.6 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 54.3/97.6 MB 72.6 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 57.6/97.6 MB 65.6 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 59.8/97.6 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 62.5/97.6 MB 59.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 65.8/97.6 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 69.0/97.6 MB 65.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 72.3/97.6 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 75.5/97.6 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 77.5/97.6 MB 65.2 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 79.7/97.6 MB 65.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 81.7/97.6 MB 54.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 85.2/97.6 MB 54.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 88.8/97.6 MB 54.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 92.3/97.6 MB 81.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  95.9/97.6 MB 73.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 97.6/97.6 MB 72.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from xformers) (1.23.5)\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "     ---------------------------------------- 0.0/172.4 MB ? eta -:--:--\n",
      "      ------------------------------------- 3.8/172.4 MB 119.7 MB/s eta 0:00:02\n",
      "     - ------------------------------------- 7.4/172.4 MB 94.9 MB/s eta 0:00:02\n",
      "     -- ----------------------------------- 11.0/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     --- ---------------------------------- 14.7/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ---- --------------------------------- 18.3/172.4 MB 72.6 MB/s eta 0:00:03\n",
      "     ---- --------------------------------- 22.0/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ----- -------------------------------- 25.7/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ------ ------------------------------- 29.4/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ------- ------------------------------ 33.1/172.4 MB 73.1 MB/s eta 0:00:02\n",
      "     -------- ----------------------------- 36.8/172.4 MB 72.6 MB/s eta 0:00:02\n",
      "     -------- ----------------------------- 40.6/172.4 MB 72.6 MB/s eta 0:00:02\n",
      "     --------- ---------------------------- 44.4/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ---------- --------------------------- 48.4/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ----------- -------------------------- 52.3/172.4 MB 93.9 MB/s eta 0:00:02\n",
      "     ------------ ------------------------- 56.2/172.4 MB 93.0 MB/s eta 0:00:02\n",
      "     ------------- ------------------------ 60.2/172.4 MB 93.0 MB/s eta 0:00:02\n",
      "     -------------- ----------------------- 64.1/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     --------------- ---------------------- 68.1/172.4 MB 93.9 MB/s eta 0:00:02\n",
      "     --------------- ---------------------- 72.1/172.4 MB 93.9 MB/s eta 0:00:02\n",
      "     ---------------- --------------------- 76.1/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ----------------- -------------------- 80.1/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ------------------ ------------------- 84.2/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     ------------------- ------------------ 88.3/172.4 MB 81.8 MB/s eta 0:00:02\n",
      "     -------------------- ----------------- 92.4/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     --------------------- ---------------- 96.6/172.4 MB 93.0 MB/s eta 0:00:01\n",
      "     --------------------- --------------- 100.8/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     ---------------------- -------------- 104.9/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     ----------------------- ------------- 109.3/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------ ------------ 113.5/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------- ----------- 117.9/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     -------------------------- ---------- 122.1/172.4 MB 93.0 MB/s eta 0:00:01\n",
      "     --------------------------- --------- 126.4/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     --------------------------- --------- 129.0/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     ---------------------------- -------- 133.4/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ------- 137.7/172.4 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------ ------ 142.0/172.4 MB 93.9 MB/s eta 0:00:01\n",
      "     ------------------------------- ----- 146.5/172.4 MB 81.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 150.9/172.4 MB 93.0 MB/s eta 0:00:01\n",
      "     -------------------------------- --- 155.3/172.4 MB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 159.7/172.4 MB 93.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 164.2/172.4 MB 93.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  168.8/172.4 MB 93.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- 172.4/172.4 MB 93.8 MB/s eta 0:00:00\n",
      "Collecting pyre-extensions==0.0.29\n",
      "  Downloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\n",
      "Collecting typing-inspect\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from pyre-extensions==0.0.29->xformers) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from torch==2.0.1->xformers) (1.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lkk68\\appdata\\roaming\\python\\python39\\site-packages (from torch==2.0.1->xformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from torch==2.0.1->xformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from torch==2.0.1->xformers) (2.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from jinja2->torch==2.0.1->xformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from sympy->torch==2.0.1->xformers) (1.2.1)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, typing-inspect, torch, pyre-extensions, xformers\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0\n",
      "    Uninstalling torch-2.0.0:\n",
      "      Successfully uninstalled torch-2.0.0\n",
      "Successfully installed mypy-extensions-1.0.0 pyre-extensions-0.0.29 torch-2.0.1 typing-inspect-0.9.0 xformers-0.0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.15.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\n",
      "torchaudio 2.0.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\n",
      "opencood 0.1.0 requires matplotlib~=3.3.3, but you have matplotlib 3.7.1 which is incompatible.\n",
      "opencood 0.1.0 requires opencv-python~=4.5.1.48, but you have opencv-python 4.7.0.72 which is incompatible.\n",
      "opencood 0.1.0 requires scipy~=1.5.4, but you have scipy 1.10.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting umap-learn\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "     ---------------------------------------- 0.0/88.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 88.2/88.2 kB 4.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from umap-learn) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from umap-learn) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from umap-learn) (1.10.1)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages\\numba-0.49.0-py3.9-win-amd64.egg (from umap-learn) (0.49.0)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 36.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from umap-learn) (4.65.0)\n",
      "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0\n",
      "  Downloading llvmlite-0.32.1.tar.gz (104 kB)\n",
      "     ---------------------------------------- 0.0/104.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 104.3/104.3 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from numba>=0.49->umap-learn) (67.7.2)\n",
      "Collecting numba>=0.49\n",
      "  Downloading numba-0.57.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ------------------------------- -------- 2.0/2.5 MB 61.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 53.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "  Downloading numba-0.57.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.6/2.6 MB 159.0 MB/s eta 0:00:00\n",
      "  Downloading numba-0.56.4-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.5/2.5 MB 152.9 MB/s eta 0:00:00\n",
      "  Downloading numba-0.56.3-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     --------------------------------- ------ 2.1/2.5 MB 129.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 39.1 MB/s eta 0:00:00\n",
      "  Downloading numba-0.56.2-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ----------------- ---------------------- 1.0/2.5 MB 64.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.1/2.5 MB 26.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 19.6 MB/s eta 0:00:00\n",
      "  Downloading numba-0.56.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ---------------- ----------------------- 1.0/2.5 MB ? eta -:--:--\n",
      "     --------------------------------- ------ 2.1/2.5 MB 33.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 19.7 MB/s eta 0:00:00\n",
      "  Downloading numba-0.55.2-cp39-cp39-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.4/2.4 MB 156.6 MB/s eta 0:00:00\n",
      "  Downloading numba-0.55.1-cp39-cp39-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "     ----------------- ---------------------- 1.0/2.4 MB ? eta -:--:--\n",
      "     ----------------------------------- ---- 2.1/2.4 MB 26.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.4/2.4 MB 18.8 MB/s eta 0:00:00\n",
      "  Downloading numba-0.55.0-cp39-cp39-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "     ----------------- ---------------------- 1.0/2.4 MB ? eta -:--:--\n",
      "     ----------------------------------- ---- 2.1/2.4 MB 26.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.4/2.4 MB 18.9 MB/s eta 0:00:00\n",
      "  Downloading numba-0.54.1-cp39-cp39-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "     ------------------ --------------------- 1.0/2.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.3/2.3 MB 37.0 MB/s eta 0:00:00\n",
      "  Downloading numba-0.54.0-cp39-cp39-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "     ------------------ --------------------- 1.0/2.3 MB 68.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.6/2.3 MB 20.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.1/2.3 MB 22.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.3/2.3 MB 14.7 MB/s eta 0:00:00\n",
      "  Downloading numba-0.53.1-cp39-cp39-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.3/2.3 MB 152.3 MB/s eta 0:00:00\n",
      "  Downloading numba-0.53.0-cp39-cp39-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "     ------------------ --------------------- 1.0/2.3 MB 64.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.1/2.3 MB 26.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.3/2.3 MB 20.8 MB/s eta 0:00:00\n",
      "  Downloading numba-0.51.2.tar.gz (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.1/2.1 MB 128.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of pynndescent to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.9.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ------------------------------------ --- 1.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 18.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 70.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading pynndescent-0.5.7.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 70.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ------------------------------------ --- 1.0/1.1 MB 68.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.1/1.1 MB 18.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading pynndescent-0.5.5.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading pynndescent-0.5.4.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading pynndescent-0.5.3.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ------------------------------------ --- 1.0/1.1 MB 68.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.1/1.1 MB 18.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of pynndescent to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading pynndescent-0.5.2.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading pynndescent-0.5.1.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ------------------------------------ --- 1.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 18.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading pynndescent-0.5.0.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 70.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.25.1-cp39-cp39-win_amd64.whl (15.1 MB)\n",
      "     ---------------------------------------- 0.0/15.1 MB ? eta -:--:--\n",
      "     ----------- ---------------------------- 4.2/15.1 MB 88.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 9.2/15.1 MB 97.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 14.2/15.1 MB 93.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 15.1/15.1 MB 108.8 MB/s eta 0:00:00\n",
      "  Downloading numpy-1.24.4-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "     --------- ----------------------------- 3.6/14.9 MB 112.0 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 7.1/14.9 MB 89.8 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 10.6/14.9 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 14.2/14.9 MB 81.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 14.9/14.9 MB 72.5 MB/s eta 0:00:00\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Downloading llvmlite-0.40.1-cp39-cp39-win_amd64.whl (27.7 MB)\n",
      "     ---------------------------------------- 0.0/27.7 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 4.9/27.7 MB 79.4 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 7.9/27.7 MB 72.2 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 11.4/27.7 MB 93.9 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 15.1/27.7 MB 72.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 18.7/27.7 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 22.3/27.7 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 26.0/27.7 MB 81.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 27.7/27.7 MB 81.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n",
      "Building wheels for collected packages: umap-learn, pynndescent\n",
      "  Building wheel for umap-learn (setup.py): started\n",
      "  Building wheel for umap-learn (setup.py): finished with status 'done'\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82909 sha256=ede3c5a68c5e27fb9fa48a03c8d04c7f117b01f3f5cb3044eb7261dc9a238bd9\n",
      "  Stored in directory: C:\\Users\\lkk68\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-te7uh8xm\\wheels\\f4\\3e\\1c\\596d0a463d17475af648688443fa4846fef624d1390339e7e9\n",
      "  Building wheel for pynndescent (setup.py): started\n",
      "  Building wheel for pynndescent (setup.py): finished with status 'done'\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55676 sha256=41dcafc3b1a3ee5dfd1b8e73f3125778596551030a0412acb4c79fa94bbed1d5\n",
      "  Stored in directory: C:\\Users\\lkk68\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-te7uh8xm\\wheels\\12\\f9\\4d\\ec5ad1c823c710fcc4473669fdcffc8891f4bc398c841af22e\n",
      "Successfully built umap-learn pynndescent\n",
      "Installing collected packages: llvmlite, numba, pynndescent, umap-learn\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.49.0\n",
      "    Uninstalling numba-0.49.0:\n",
      "      Successfully uninstalled numba-0.49.0\n",
      "Successfully installed llvmlite-0.40.1 numba-0.57.1 pynndescent-0.5.10 umap-learn-0.5.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencood 0.1.0 requires matplotlib~=3.3.3, but you have matplotlib 3.7.1 which is incompatible.\n",
      "opencood 0.1.0 requires numba==0.49.0, but you have numba 0.57.1 which is incompatible.\n",
      "opencood 0.1.0 requires opencv-python~=4.5.1.48, but you have opencv-python 4.7.0.72 which is incompatible.\n",
      "opencood 0.1.0 requires scipy~=1.5.4, but you have scipy 1.10.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "ref: https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/04_multilingual-ner.ipynb\n",
    "https://www.oreilly.com/library/view/natural-language-processing/9781098136789/ch04.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>Jeff</td>\n",
       "      <td>Dean</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>computer</td>\n",
       "      <td>scientist</td>\n",
       "      <td>at</td>\n",
       "      <td>Google</td>\n",
       "      <td>in</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1   2  3         4          5   6       7   8           9\n",
       "Tokens   Jeff   Dean  is  a  computer  scientist  at  Google  in  California\n",
       "Tags    B-PER  I-PER   O  O         O          O   O   B-ORG   O       B-LOC"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "toks = \"Jeff Dean is a computer scientist at Google in California\".split()\n",
    "lbls = [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"B-LOC\"]\n",
    "df = pd.DataFrame(data=[toks, lbls], index=['Tokens', 'Tags'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32a25ec8b6c4e4bad5fdb6b9e0019e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/37.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10398ee55663460581f7cd7da42400fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/593k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a8bfb1683043d796455a362ed9a5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/105k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "#https://huggingface.co/datasets/xtreme\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XNLI',\n",
       " 'tydiqa',\n",
       " 'SQuAD',\n",
       " 'PAN-X.af',\n",
       " 'PAN-X.ar',\n",
       " 'PAN-X.bg',\n",
       " 'PAN-X.bn',\n",
       " 'PAN-X.de',\n",
       " 'PAN-X.el',\n",
       " 'PAN-X.en',\n",
       " 'PAN-X.es',\n",
       " 'PAN-X.et',\n",
       " 'PAN-X.eu',\n",
       " 'PAN-X.fa',\n",
       " 'PAN-X.fi',\n",
       " 'PAN-X.fr',\n",
       " 'PAN-X.he',\n",
       " 'PAN-X.hi',\n",
       " 'PAN-X.hu',\n",
       " 'PAN-X.id',\n",
       " 'PAN-X.it',\n",
       " 'PAN-X.ja',\n",
       " 'PAN-X.jv',\n",
       " 'PAN-X.ka',\n",
       " 'PAN-X.kk',\n",
       " 'PAN-X.ko',\n",
       " 'PAN-X.ml',\n",
       " 'PAN-X.mr',\n",
       " 'PAN-X.ms',\n",
       " 'PAN-X.my',\n",
       " 'PAN-X.nl',\n",
       " 'PAN-X.pt',\n",
       " 'PAN-X.ru',\n",
       " 'PAN-X.sw',\n",
       " 'PAN-X.ta',\n",
       " 'PAN-X.te',\n",
       " 'PAN-X.th',\n",
       " 'PAN-X.tl',\n",
       " 'PAN-X.tr',\n",
       " 'PAN-X.ur',\n",
       " 'PAN-X.vi',\n",
       " 'PAN-X.yo',\n",
       " 'PAN-X.zh',\n",
       " 'MLQA.ar.ar',\n",
       " 'MLQA.ar.de',\n",
       " 'MLQA.ar.vi',\n",
       " 'MLQA.ar.zh',\n",
       " 'MLQA.ar.en',\n",
       " 'MLQA.ar.es',\n",
       " 'MLQA.ar.hi',\n",
       " 'MLQA.de.ar',\n",
       " 'MLQA.de.de',\n",
       " 'MLQA.de.vi',\n",
       " 'MLQA.de.zh',\n",
       " 'MLQA.de.en',\n",
       " 'MLQA.de.es',\n",
       " 'MLQA.de.hi',\n",
       " 'MLQA.vi.ar',\n",
       " 'MLQA.vi.de',\n",
       " 'MLQA.vi.vi',\n",
       " 'MLQA.vi.zh',\n",
       " 'MLQA.vi.en',\n",
       " 'MLQA.vi.es',\n",
       " 'MLQA.vi.hi',\n",
       " 'MLQA.zh.ar',\n",
       " 'MLQA.zh.de',\n",
       " 'MLQA.zh.vi',\n",
       " 'MLQA.zh.zh',\n",
       " 'MLQA.zh.en',\n",
       " 'MLQA.zh.es',\n",
       " 'MLQA.zh.hi',\n",
       " 'MLQA.en.ar',\n",
       " 'MLQA.en.de',\n",
       " 'MLQA.en.vi',\n",
       " 'MLQA.en.zh',\n",
       " 'MLQA.en.en',\n",
       " 'MLQA.en.es',\n",
       " 'MLQA.en.hi',\n",
       " 'MLQA.es.ar',\n",
       " 'MLQA.es.de',\n",
       " 'MLQA.es.vi',\n",
       " 'MLQA.es.zh',\n",
       " 'MLQA.es.en',\n",
       " 'MLQA.es.es',\n",
       " 'MLQA.es.hi',\n",
       " 'MLQA.hi.ar',\n",
       " 'MLQA.hi.de',\n",
       " 'MLQA.hi.vi',\n",
       " 'MLQA.hi.zh',\n",
       " 'MLQA.hi.en',\n",
       " 'MLQA.hi.es',\n",
       " 'MLQA.hi.hi',\n",
       " 'XQuAD.ar',\n",
       " 'XQuAD.de',\n",
       " 'XQuAD.vi',\n",
       " 'XQuAD.zh',\n",
       " 'XQuAD.en',\n",
       " 'XQuAD.es',\n",
       " 'XQuAD.hi',\n",
       " 'XQuAD.el',\n",
       " 'XQuAD.ru',\n",
       " 'XQuAD.th',\n",
       " 'XQuAD.tr',\n",
       " 'bucc18.de',\n",
       " 'bucc18.fr',\n",
       " 'bucc18.zh',\n",
       " 'bucc18.ru',\n",
       " 'PAWS-X.de',\n",
       " 'PAWS-X.en',\n",
       " 'PAWS-X.es',\n",
       " 'PAWS-X.fr',\n",
       " 'PAWS-X.ja',\n",
       " 'PAWS-X.ko',\n",
       " 'PAWS-X.zh',\n",
       " 'tatoeba.afr',\n",
       " 'tatoeba.ara',\n",
       " 'tatoeba.ben',\n",
       " 'tatoeba.bul',\n",
       " 'tatoeba.deu',\n",
       " 'tatoeba.cmn',\n",
       " 'tatoeba.ell',\n",
       " 'tatoeba.est',\n",
       " 'tatoeba.eus',\n",
       " 'tatoeba.fin',\n",
       " 'tatoeba.fra',\n",
       " 'tatoeba.heb',\n",
       " 'tatoeba.hin',\n",
       " 'tatoeba.hun',\n",
       " 'tatoeba.ind',\n",
       " 'tatoeba.ita',\n",
       " 'tatoeba.jav',\n",
       " 'tatoeba.jpn',\n",
       " 'tatoeba.kat',\n",
       " 'tatoeba.kaz',\n",
       " 'tatoeba.kor',\n",
       " 'tatoeba.mal',\n",
       " 'tatoeba.mar',\n",
       " 'tatoeba.nld',\n",
       " 'tatoeba.pes',\n",
       " 'tatoeba.por',\n",
       " 'tatoeba.rus',\n",
       " 'tatoeba.spa',\n",
       " 'tatoeba.swh',\n",
       " 'tatoeba.tam',\n",
       " 'tatoeba.tel',\n",
       " 'tatoeba.tgl',\n",
       " 'tatoeba.tha',\n",
       " 'tatoeba.tur',\n",
       " 'tatoeba.urd',\n",
       " 'tatoeba.vie',\n",
       " 'udpos.Afrikaans',\n",
       " 'udpos.Arabic',\n",
       " 'udpos.Basque',\n",
       " 'udpos.Bulgarian',\n",
       " 'udpos.Dutch',\n",
       " 'udpos.English',\n",
       " 'udpos.Estonian',\n",
       " 'udpos.Finnish',\n",
       " 'udpos.French',\n",
       " 'udpos.German',\n",
       " 'udpos.Greek',\n",
       " 'udpos.Hebrew',\n",
       " 'udpos.Hindi',\n",
       " 'udpos.Hungarian',\n",
       " 'udpos.Indonesian',\n",
       " 'udpos.Italian',\n",
       " 'udpos.Japanese',\n",
       " 'udpos.Kazakh',\n",
       " 'udpos.Korean',\n",
       " 'udpos.Chinese',\n",
       " 'udpos.Marathi',\n",
       " 'udpos.Persian',\n",
       " 'udpos.Portuguese',\n",
       " 'udpos.Russian',\n",
       " 'udpos.Spanish',\n",
       " 'udpos.Tagalog',\n",
       " 'udpos.Tamil',\n",
       " 'udpos.Telugu',\n",
       " 'udpos.Thai',\n",
       " 'udpos.Turkish',\n",
       " 'udpos.Urdu',\n",
       " 'udpos.Vietnamese',\n",
       " 'udpos.Yoruba']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtreme_subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtreme datasets subsets used are: PAN-X.{lang}. Language used for training/validation are: italian, english, german, french and spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.de to C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0790182e7e064cd4b55533f6fc5553a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7874ed22cc0240f8ad1f2666ec174f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8088ee3a3ede463995114202a72398cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb31696621194b0baa1144197772acd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4347b0d4954db3913130fb793e76b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "load_dataset(\"xtreme\", name=\"PAN-X.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xtreme (C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b2df27f50d4d34a4368de9ecf42d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.fr to C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab52504efc448cc99312023a4385d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889a8d2a35274ea0a1cffc34390f9b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e940ecfdb294916b8369609b90b3fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2f6ea2fb584263abc87ef970598217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.it to C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c8ec3c05b4480891ca8a8d9d568aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaae6e38b7894890b94abb82c3008405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8136757f474b50b35d4cb612a84d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b22df558daf4d019ded64b3b7c3fdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.en to C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58056ab515d446393206299392a79f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956d436d5e014612b1b6c6f36fd19095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a08719cc6a4611ae4f03935cd8bdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to C:/Users/lkk68/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954cc8fb5d334210a8ef0932b2311070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# Return a DatasetDict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "            .shuffle(seed=0)\n",
    "            .select(range(int(frac * ds[split].num_rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "             index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O means the word doesn’t correspond to any entity.\n",
    "B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n",
    "B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n",
    "B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n",
    "B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can access the list of names by looking at the names attribute of that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257a3a28a70840a39b8d3e266b02e5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a462448fb69b4b2b9413d1db8f552f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79334b7e1a54735a9925a66eb922d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca44cceab64e49038f482affe9e214f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14433162c0bf4fc1be0e4918e65820a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1395b2e1d6437cb99acbffcac59d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BERT</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Spa</td>\n",
       "      <td>##rrow</td>\n",
       "      <td>loves</td>\n",
       "      <td>New</td>\n",
       "      <td>York</td>\n",
       "      <td>!</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLM-R</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2       3      4    5     6      7      8     9\n",
       "BERT   [CLS]   Jack    Spa  ##rrow  loves  New  York      !  [SEP]  None\n",
       "XLM-R    <s>  ▁Jack  ▁Spar     row  ▁love    s  ▁New  ▁York      !  </s>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([bert_tokens, xlmr_tokens], index=[\"BERT\", \"XLM-R\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers is designed to enable you to easily extend existing models for your specific use case. You can load the weights from pretrained models, and you have access to task-specific helper functions. This lets you build custom models for specific objectives with very little overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    #With the super() method we call the initialization function of the RobertaPreTrainedModel class. \n",
    "    #This abstract class handles the initialization or loading of pretrained weights.\n",
    "\n",
    "    #The config_class ensures that the standard XLM-R settings are used when we initialize a new model\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        #set add_​pool⁠ing_layer=False to ensure all hidden states are returned and not only the one associated with the [CLS] token\n",
    "\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Load and initialize weights, which will load the pretrained weights for the model body and randomly initialize the weights of our token classification head\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
    "                labels=None, **kwargs):\n",
    "        # There are a number of input variables, but the only ones we need for now are input_ids and attention_mask.\n",
    "\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        \n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        # Return model output object that wrap all the outputs in a TokenClassifierOutput object that allows us to access elements in a the familiar named tuple\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, \n",
    "                                     hidden_states=outputs.hidden_states, \n",
    "                                     attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All  information can be derived from tags variable, which as a ClassLabel object has a names attribute that we can use to derive the mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " -100: 'IGN'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "#We’ll store these mappings and the tags.num_classes attribute in the AutoConfig object\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c7a353ac824f289643070a1f5e3c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xlmr_model = (XLMRobertaForTokenClassification\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jack Sparrow loves New York!'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the predictions on our small sequence of known entities:\n",
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the start <s> and end </s> tokens are given the IDs 0 and 2, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs, dim=-1) #get the most likely class per token:\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the logits have the shape [batch_size, num_tokens, num_tags], with each token given a logit among the seven possible NER tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      9\n",
       "Tokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\n",
       "Tags    I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap the preceding steps into a helper function for later use\n",
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # Get tokens with special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    # Encode the sequence into IDs\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    # Get predictions as distribution over 7 possible classes\n",
    "    outputs = model(input_ids)[0]\n",
    "    # Take argmax to get most likely class per token\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    # Convert to DataFrame\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.000',\n",
       " 'Einwohnern',\n",
       " 'an',\n",
       " 'der',\n",
       " 'Danziger',\n",
       " 'Bucht',\n",
       " 'in',\n",
       " 'der',\n",
       " 'polnischen',\n",
       " 'Woiwodschaft',\n",
       " 'Pommern',\n",
       " '.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15  \\\n",
       "Tokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tokens], index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we can see that the tokenizer has split “Einwohnern” into two subwords, “▁Einwohner” and “n”. Since we’re following the convention that only “▁Einwohner” should be associated with the B-LOC label, we need a way to mask the subword representations after the first subword. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenized_input is a class that contains a word_ids() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "Word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that word_ids has mapped each subword to the corresponding index in the words sequence, so the first subword, “▁2.000”, is assigned the index 0, while “▁Einwohner” and “n” are assigned the index 1 (since “Einwohnern” is the second word in words). We can also see that special tokens like <s> and <\\s> are mapped to None. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let’s set –100 as the label for these special tokens and the subwords we wish to mask during training:\n",
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "    \n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason of using \"-100\" is that in PyTorch the cross-entropy loss class torch.nn.CrossEntropyLoss has an attribute called ignore_index whose value is –100. This index is ignored during training, so we can use it to ignore the tokens associated with consecutive subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale this out to the whole dataset by defining a single function that wraps all the logic\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, \n",
    "                                      is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True, \n",
    "                      remove_columns=['langs', 'ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfeddfb80614381a8af05cbd1201103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9715b32aec643c5b461bbb200347c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4afa6e903b42a9a62ff4013e5ceb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#By applying this function to a DatasetDict object, we get an encoded Dataset object per split.\n",
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating a NER model is similar to evaluating a text classification model, and it is common to report results for precision, recall, and F1-score. The only subtlety is that all words of an entity need to be predicted correctly in order for a prediction to be counted as correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is a nifty library called seqeval that is designed for these kinds of tasks. For example, given some placeholder NER tags and model predictions, we can compute the metrics via seqeval’s classification_report() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "#seqeval expects the predictions and labels as lists of lists, with each list corresponding to a single example in our validation or test sets\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#take the outputs of the model and convert them into the lists that seqeval expects.\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine-tune our base model on the German subset of PAN-X and then evaluate its zero-shot cross-lingual performance on French, Italian, and English.\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\", \n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, \n",
    "    logging_steps=logging_steps, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this in colab, has copy-paste issues in VSCode Jupyter\n",
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()\n",
    "\n",
    "#if you’re working in a terminal, you can execute the command huggingface-cli login instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token='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') #(token=os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions, \n",
    "                                       eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a data collator so we can pad each input sequence to the largest sequence length in a batch\n",
    "\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "#Transformers provides a dedicated data collator for token classification that will pad the labels along with the inputs:\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)\n",
    "\n",
    "#One important detail here is that the label sequences are padded with the value –100, which is ignored by PyTorch loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid initializing a new model for every Trainer by creating a model_init() method. \n",
    "#This method loads an untrained model and is called at the beginning of the train() call:\n",
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/lkk688/xlm-roberta-base-finetuned-panx-de into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args, \n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=panx_de_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_encoded[\"validation\"], \n",
    "                  tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lkk68\\.conda\\envs\\mycondapy39\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1575' max='1575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1575/1575 2:30:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.155403</td>\n",
       "      <td>0.824107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.137574</td>\n",
       "      <td>0.847460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.138066</td>\n",
       "      <td>0.856770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2849c14bc1432399552601f6715823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25ac60ac2e4476bb65283d5fa3e051a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file tokenizer.json:   0%|          | 1.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634a11b9c12a4e2188f5eddce05d1e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Jul30_10-13-21_newalienware/events.out.tfevents.1690737628.newalienware.11276.0:   0%|       …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03029ad8b6814de689e8fa63a2ccbc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file sentencepiece.bpe.model:   0%|          | 1.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa5b925b31e4e139c8d8e649ee41e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin:   0%|          | 1.00/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/lkk688/xlm-roberta-base-finetuned-panx-de\n",
      "   011def8..4afded2  main -> main\n",
      "\n",
      "To https://huggingface.co/lkk688/xlm-roberta-base-finetuned-panx-de\n",
      "   4afded2..4d77417  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/lkk688/xlm-roberta-base-finetuned-panx-de/commit/4afded2b11c4cbc4de8d9a942f9f9a5906b5af60'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the training loop and push the final model to the Hub\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁ist</td>\n",
       "      <td>▁ein</td>\n",
       "      <td>▁Informati</td>\n",
       "      <td>ker</td>\n",
       "      <td>▁bei</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Kaliforni</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3     4     5           6    7     8   \\\n",
       "Tokens    <s>  ▁Jeff    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei   \n",
       "Tags    B-PER  B-PER  I-PER  I-PER     O     O           O    O     O   \n",
       "\n",
       "             9    10          11     12    13  \n",
       "Tokens  ▁Google  ▁in  ▁Kaliforni     en  </s>  \n",
       "Tags      B-ORG    O       B-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(trainer.state.log_history)[['epoch','loss' ,'eval_loss', 'eval_f1']]\n",
    "df = df.rename(columns={\"epoch\":\"Epoch\",\"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", \"eval_f1\":\"F1\"})\n",
    "df['Epoch'] = df[\"Epoch\"].apply(lambda x: round(x))\n",
    "df['Training Loss'] = df[\"Training Loss\"].ffill()\n",
    "df[['Validation Loss', 'F1']] = df[['Validation Loss', 'F1']].bfill().ffill()\n",
    "df.drop_duplicates()\n",
    "\n",
    "#test it on the German translation of our simple example\n",
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model  \n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # Logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7), \n",
    "                         labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function forward_pass_with_label at 0x00000257B0550F70> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475d2ac4ee6240588b10d0f615ce2523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#apply this forward function to the whole validation set using map() and \n",
    "#load all the data into a DataFrame\n",
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels', 'loss', 'predicted_label'],\n",
       "    num_rows: 6290\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 0.028938925, 0.0, 0.01902312, 0.01418072...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            input_ids         attention_mask  \\\n",
       "0  [0, 10699, 11, 15, 16104, 1388, 2]  [1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                        labels  \\\n",
       "0  [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.028938925, 0.0, 0.01902312, 0.01418072...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]   \n",
       "\n",
       "                                 input_tokens  \n",
       "0  [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For the padding tokens with label –100 we assign a special label, IGN, so we can filter them later.\n",
    "#We also get rid of all the padding in the loss and predicted_label fields by truncating them to the length of the inputs\n",
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df['loss'] = df.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df['predicted_label'] = df.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10699</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16104</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.01</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56530</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁WE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83982</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.42</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Luz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.32</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label  input_tokens\n",
       "0     10699              1  B-ORG  0.03           B-ORG          ▁Ham\n",
       "0        15              1  I-ORG  0.02           I-ORG            ▁(\n",
       "0     16104              1  I-ORG  0.01           I-ORG  ▁Unternehmen\n",
       "0      1388              1  I-ORG  0.02           I-ORG            ▁)\n",
       "1     56530              1      O  0.00               O           ▁WE\n",
       "1     83982              1  B-ORG  0.42           B-ORG          ▁Luz\n",
       "1        10              1  I-ORG  0.32           I-ORG            ▁a"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The pan⁠das.Series.explode() function allows creating a row for each element in the original rows list. \n",
    "df_tokens = df.apply(pd.Series.explode)\n",
    "#drop the padding tokens 'IGN'\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "#cast the losses, which are still numpy.Array objects, to standard floats\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now group it by the input tokens and aggregate the losses for each token with the count, mean, and sum. Finally, we sort the aggregated data by the sum of the losses and see which tokens have accumulated the most loss in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁/</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>989</td>\n",
       "      <td>1388</td>\n",
       "      <td>808</td>\n",
       "      <td>1171</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>163</td>\n",
       "      <td>2898</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>215.4</td>\n",
       "      <td>136.89</td>\n",
       "      <td>127.97</td>\n",
       "      <td>111.35</td>\n",
       "      <td>89.13</td>\n",
       "      <td>85.38</td>\n",
       "      <td>79.64</td>\n",
       "      <td>74.41</td>\n",
       "      <td>72.85</td>\n",
       "      <td>52.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3      4      5      6      7  \\\n",
       "input_tokens      ▁     ▁in    ▁der    ▁von   ▁und     ▁(     ▁)     ▁/   \n",
       "count          6066     989    1388     808   1171    246    246    163   \n",
       "mean           0.04    0.14    0.09    0.14   0.08   0.35   0.32   0.46   \n",
       "sum           215.4  136.89  127.97  111.35  89.13  85.38  79.64  74.41   \n",
       "\n",
       "                  8      9  \n",
       "input_tokens    ▁''     ▁A  \n",
       "count          2898    125  \n",
       "mean           0.03   0.42  \n",
       "sum           72.85  52.05  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above list: 1) The whitespace token has the highest total loss, which is not surprising since it is also the most common token in the list. However, its mean loss is much lower than the other tokens in the list. This means that the model doesn’t struggle to classify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1462</td>\n",
       "      <td>2683</td>\n",
       "      <td>3820</td>\n",
       "      <td>3172</td>\n",
       "      <td>2893</td>\n",
       "      <td>4139</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>978.36</td>\n",
       "      <td>1626.55</td>\n",
       "      <td>1806.32</td>\n",
       "      <td>1098.07</td>\n",
       "      <td>767.0</td>\n",
       "      <td>768.86</td>\n",
       "      <td>1439.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2        3      4       5        6\n",
       "labels   I-LOC    B-ORG    I-ORG    B-LOC  B-PER   I-PER        O\n",
       "count     1462     2683     3820     3172   2893    4139    43648\n",
       "mean      0.67     0.61     0.47     0.35   0.27    0.19     0.03\n",
       "sum     978.36  1626.55  1806.32  1098.07  767.0  768.86  1439.92"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group the label IDs and look at the losses for each class\n",
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]] \n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .sort_values(by=\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"],\n",
    "                      tags.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁Τ</td>\n",
       "      <td>Κ</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁T</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ri</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>k</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ala</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.34</td>\n",
       "      <td>10.24</td>\n",
       "      <td>9.18</td>\n",
       "      <td>6.86</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.55</td>\n",
       "      <td>8.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2      3     4     5      6      7      8      9   \\\n",
       "tokens    ▁'   ▁''     ▁Τ      Κ   ▁''    ▁'     ▁'    ▁''     ▁T    ▁''   \n",
       "labels     O     O      O    IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \n",
       "preds      O     O  B-ORG  I-ORG     O     O      O      O  B-ORG      O   \n",
       "losses  0.00  0.00   4.02   0.00  0.00  0.00  10.34  10.24   9.18   6.86   \n",
       "\n",
       "           10    11     12     13    14     15     16    17    18  \n",
       "tokens     ▁'    ri    ▁''     ▁'     k    ▁''     ▁'   ala  </s>  \n",
       "labels  I-LOC   IGN  I-LOC  I-LOC   IGN  I-LOC  I-LOC   IGN   IGN  \n",
       "preds       O     O      O      O     O      O      O     O     O  \n",
       "losses   8.25  0.00   7.55   8.23  0.00   8.12   8.00  0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁United</td>\n",
       "      <td>▁Nations</td>\n",
       "      <td>▁Multi</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>▁Integra</td>\n",
       "      <td>ted</td>\n",
       "      <td>▁Stabil</td>\n",
       "      <td>ization</td>\n",
       "      <td>▁Mission</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁Central</td>\n",
       "      <td>▁African</td>\n",
       "      <td>▁Republic</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>6.37</td>\n",
       "      <td>6.19</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.26</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.48</td>\n",
       "      <td>6.24</td>\n",
       "      <td>5.93</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1       2            3         4      5        6   \\\n",
       "tokens  ▁United  ▁Nations  ▁Multi  dimensional  ▁Integra    ted  ▁Stabil   \n",
       "labels    B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \n",
       "preds     B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \n",
       "losses     6.37      6.19    7.05         0.00      6.91   0.00     6.71   \n",
       "\n",
       "             7         8      9      10        11        12         13     14  \n",
       "tokens  ization  ▁Mission    ▁in   ▁the  ▁Central  ▁African  ▁Republic   </s>  \n",
       "labels      IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER    IGN  \n",
       "preds     I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  I-ORG  \n",
       "losses     0.00      6.26   6.59   6.82      6.48      6.24       5.93   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁''</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>▁Juli</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁:</td>\n",
       "      <td>▁Protest</td>\n",
       "      <td>camp</td>\n",
       "      <td>▁auf</td>\n",
       "      <td>▁dem</td>\n",
       "      <td>▁Gelände</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Republika</td>\n",
       "      <td>n</td>\n",
       "      <td>ischen</td>\n",
       "      <td>▁Gar</td>\n",
       "      <td>de</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>7.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.21</td>\n",
       "      <td>9.15</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.29</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.05</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2      3      4      5         6     7      8      9   \\\n",
       "tokens    ▁''     8     .  ▁Juli    ▁''     ▁:  ▁Protest  camp   ▁auf   ▁dem   \n",
       "labels  B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG  I-ORG   \n",
       "preds       O     O     O      O      O      O         O     O      O      O   \n",
       "losses   7.59  0.00  0.00   5.25   9.21   9.15      6.05  0.00   7.29   8.75   \n",
       "\n",
       "              10     11          12     13      14     15     16    17  \n",
       "tokens  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de  </s>  \n",
       "labels     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN   IGN  \n",
       "preds          O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG     O  \n",
       "losses      7.05   5.24        3.11   0.00    0.00   0.01   0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display the token sequences with the labels and the losses\n",
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \n",
    "                               \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp\n",
    "\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parentheses and slashes had a relatively high loss. Let’s look at a few examples of sequences with an opening parenthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Ham</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2             3      4      5\n",
       "tokens   ▁Ham      a     ▁(  ▁Unternehmen     ▁)   </s>\n",
       "labels  B-ORG    IGN  I-ORG         I-ORG  I-ORG    IGN\n",
       "preds   B-ORG  I-ORG  I-ORG         I-ORG  I-ORG  I-ORG\n",
       "losses   0.03   0.00   0.02          0.01   0.02   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Kesk</td>\n",
       "      <td>kül</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Mart</td>\n",
       "      <td>na</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7\n",
       "tokens  ▁Kesk    kül      a     ▁(  ▁Mart     na     ▁)   </s>\n",
       "labels  B-LOC    IGN    IGN  I-LOC  I-LOC    IGN  I-LOC    IGN\n",
       "preds   B-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\n",
       "losses   0.02   0.00   0.00   0.02   0.02   0.00   0.02   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Lingual Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate its ability to transfer to other languages via the predict() method of the Trainer\n",
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We can use this function to examine the performance on the test set and keep track of our scores in a dict:\n",
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁est</td>\n",
       "      <td>▁informatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>▁chez</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁en</td>\n",
       "      <td>▁Cali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3     4            5    6      7        8   \\\n",
       "Tokens    <s>  ▁Jeff    ▁De     an  ▁est  ▁informatic  ien  ▁chez  ▁Google   \n",
       "Tags    B-PER  B-PER  I-PER  I-PER     O            O    O      O    B-ORG   \n",
       "\n",
       "         9      10     11     12    13  \n",
       "Tokens  ▁en  ▁Cali    for    nie  </s>  \n",
       "Tags      O  B-LOC  I-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see how our model fine-tuned on German fares on French:\n",
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let’s quantify how well our German model fares on the whole French test set by writing a simple function that encodes a dataset and generates the classification report on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6c3e1187d74623bb478db7f92c59bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769933538b9b4d23bcd170919f8b535f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387a3de0559d46cda6a26d43134761f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7047282084271469"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores['de']['fr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the performance on Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4ae334badd4f79aec15a4409178e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25224cb90ac4c5e840b59e4d10158d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c933fd87a9be441198c0a7a6eaaf09d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6912637828668362"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores['de']['it']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examine the performance on English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccca26cd6ac40bdad139c4adffb40ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630934b04716428d887db17d91f6fb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b862fee8924221ba9671dff95ca3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['de']['en']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycondapy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
